{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdat-tht225482\u001b[0m (\u001b[33mdat-tht225482-hust\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Utility\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from models.custom import RatingDataset\n",
    "from models.cb import FeatureGenerator\n",
    "from models.hybrid import EmbededHybridNet\n",
    "from models.training import train_model, test_model\n",
    "from utility import Mapper\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using \" + DEVICE)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 200948\n",
      "Number of items: 84432\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"merged/full\"\n",
    "mapper = Mapper.load(f\"./database/{DATASET}/pydata/mapper.pkl\")\n",
    "full_mapper = Mapper.load(f\"./database/merged/mapper.pkl\")\n",
    "data = RatingDataset(f\"./database/{DATASET}\", full_mapper, True)\n",
    "print(\"Number of users:\", NUM_USER := len(mapper.user_fwd_map))\n",
    "print(\"Number of items:\", NUM_ITEM := len(mapper.item_fwd_map))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "EPOCHS = 20\n",
    "BATCH = 4096\n",
    "SEED = 291124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ad14826b09427badf7ccfa2fabd48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113010955555561, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/zelinix_window/workspace/movie-recommendation/wandb/run-20241227_064056-71a74a4m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dat-tht225482-hust/movie-recommendation-models/runs/71a74a4m' target=\"_blank\">rural-brook-64</a></strong> to <a href='https://wandb.ai/dat-tht225482-hust/movie-recommendation-models' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dat-tht225482-hust/movie-recommendation-models' target=\"_blank\">https://wandb.ai/dat-tht225482-hust/movie-recommendation-models</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dat-tht225482-hust/movie-recommendation-models/runs/71a74a4m' target=\"_blank\">https://wandb.ai/dat-tht225482-hust/movie-recommendation-models/runs/71a74a4m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dat-tht225482-hust/movie-recommendation-models/runs/71a74a4m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f98792e6270>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"movie-recommendation-models\",\n",
    "    resume=\"allow\",\n",
    "    config={\n",
    "        \"dataset\": DATASET,\n",
    "        \"seed\": SEED,\n",
    "        \"batch_size\": BATCH,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"device\": DEVICE,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.split(0.8, seed=SEED)\n",
    "train_loader = DataLoader(train, batch_size=BATCH, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_uniform_rule(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0 / np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = torch.load(\"./models/cb/genres_with_ratings.pt\").to(DEVICE)\n",
    "titles_and_plots = torch.load(\"./models/cb/titles_and_plots.pt\").to(DEVICE)\n",
    "directors_and_casts = torch.load(\"./models/cb/directors_and_cast.pt\").to(DEVICE)\n",
    "model = EmbededHybridNet(NUM_USER, genres, titles_and_plots, directors_and_casts).to(DEVICE)\n",
    "# model.apply(init_uniform_rule)\n",
    "model.load_state_dict(torch.load(\"./model.pth\"))\n",
    "loss_fn = nn.MSELoss()\n",
    "l1 = nn.L1Loss()\n",
    "optimizer = optim.SGD(model.parameters())\n",
    "best_val_loss = float(\"inf\")\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbededHybridNet(\n",
       "  (item_weighted_genres): FeatureGenerator()\n",
       "  (item_titles_plots): FeatureGenerator()\n",
       "  (item_directors_casts): FeatureGenerator()\n",
       "  (user_weighted_genres): Embedding(200948, 20, sparse=True)\n",
       "  (user_titles_plots): Embedding(200948, 2280, sparse=True)\n",
       "  (user_directors_casts): Embedding(200948, 482, sparse=True)\n",
       "  (dense_weighted_genres): Linear(in_features=40, out_features=2, bias=True)\n",
       "  (dense_titles_plots): Linear(in_features=4560, out_features=20, bias=True)\n",
       "  (dense_directors_casts): Linear(in_features=964, out_features=10, bias=True)\n",
       "  (out): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging(epoch, train_loss, train_mae, test_loss, test_mae, time):\n",
    "    time = int(time)\n",
    "    logs = \"\"\n",
    "    logs += f\"Epoch {epoch}: \"\n",
    "    logs += f\"Train Loss: {train_loss:.4e} | \"\n",
    "    logs += f\"Train MAE: {train_mae:.4e} | \"\n",
    "    logs += f\"Test Loss: {test_loss:.4e} | \"\n",
    "    logs += f\"Test MAE: {test_mae:.4e} | \"\n",
    "    logs += f\"Time Taken: {time // 60}m {time % 60:02d}s\"\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_mae\": train_mae,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_mae\": test_mae,\n",
    "        }\n",
    "    )\n",
    "    print(logs, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- Training: Batch 948/6251\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m     train_loss, train_mae \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     test_loss, test_mae \u001b[38;5;241m=\u001b[39m test_model(epoch, model, test_loader, loss_fn, DEVICE)\n\u001b[1;32m      7\u001b[0m     time_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/workspace/movie-recommendation/models/training.py:21\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(epoch, model, dataloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m train_mae \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     20\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrating\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrating\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/vocalopy/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/vocalopy/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/vocalopy/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/workspace/movie-recommendation/models/custom.py:50\u001b[0m, in \u001b[0;36mRatingDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUserID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     49\u001b[0m movie \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMovieID\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 50\u001b[0m rating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper:\n\u001b[1;32m     52\u001b[0m     user \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper\u001b[38;5;241m.\u001b[39muser_fwd_map[user]\n",
      "File \u001b[0;32m~/anaconda3/envs/vocalopy/lib/python3.12/site-packages/pandas/core/series.py:1088\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   1087\u001b[0m     check_dict_or_set_indexers(key)\n\u001b[0;32m-> 1088\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_if_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n\u001b[1;32m   1091\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mor\u001b[39;00m warn_copy_on_write():\n",
      "File \u001b[0;32m~/anaconda3/envs/vocalopy/lib/python3.12/site-packages/pandas/core/common.py:372\u001b[0m, in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;66;03m# everything failed (probably because the argument\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;66;03m# wasn't actually callable); we return None\u001b[39;00m\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# instead of the empty string in this case to allow\u001b[39;00m\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# distinguishing between no name and a name of ''\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_if_callable\u001b[39m(maybe_callable, obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    373\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    Evaluate possibly callable input using obj and kwargs if it is callable,\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    otherwise return as it is.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    **kwargs\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(maybe_callable):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_mae = train_model(\n",
    "        epoch, model, train_loader, loss_fn, optimizer, DEVICE\n",
    "    )\n",
    "    test_loss, test_mae = test_model(epoch, model, test_loader, loss_fn, DEVICE)\n",
    "    time_taken = time.time() - start_time\n",
    "    logging(epoch, train_loss, train_mae, test_loss, test_mae, time_taken)\n",
    "    if test_loss < best_val_loss:\n",
    "        best_val_loss = test_loss\n",
    "        torch.save(model.state_dict(), \"model.pth\")\n",
    "        print(\"> Checkpoint saved!\")\n",
    "    else:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(\"./database/merged/metadatas.csv\")\n",
    "full_mapper = Mapper.load(f\"./database/merged/mapper.pkl\")\n",
    "model = EmbededHybridNet(NUM_USER, genres, titles_and_plots, directors_and_casts).to(DEVICE)\n",
    "# model.load_state_dict(torch.load(\"./models/hybrid/embeded_hybrid.pth\"))\n",
    "model.load_state_dict(torch.load(\"./model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation(user, model: nn.Module, top: int = 10):\n",
    "    user_idx = int(full_mapper.user_fwd_map[user])\n",
    "    num_items = len(full_mapper.item_fwd_map)\n",
    "    users = torch.tensor([user_idx] * num_items, dtype=torch.int64, device=DEVICE)\n",
    "    movies = torch.tensor(range(num_items), dtype=torch.int64, device=DEVICE)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        ratings: torch.Tensor = model(users, movies)\n",
    "    ratings = [\n",
    "        (full_mapper.item_inv_map[i], float(r.item()))\n",
    "        for i, r in zip(range(num_items), ratings.to(\"cpu\"))\n",
    "    ]\n",
    "    ratings = sorted(ratings, key=lambda x: x[1], reverse=True)[:top]\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>V for Vendetta (2006)</td>\n",
       "      <td>44191</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Curse of Aurore (2020)</td>\n",
       "      <td>239172</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Da Vinci Code, The (2006)</td>\n",
       "      <td>45447</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Transporter, The (2002)</td>\n",
       "      <td>5574</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bruce Almighty (2003)</td>\n",
       "      <td>6373</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Belzebuth (2019)</td>\n",
       "      <td>204584</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Expendables 2, The (2012)</td>\n",
       "      <td>91485</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>The Dark Web Tapes (2020)</td>\n",
       "      <td>287423</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Angels &amp; Demons (2009)</td>\n",
       "      <td>68554</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Apartment 143 (2011)</td>\n",
       "      <td>96634</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  MovieID  Rating\n",
       "40       V for Vendetta (2006)    44191     4.5\n",
       "130     Curse of Aurore (2020)   239172     2.5\n",
       "42   Da Vinci Code, The (2006)    45447     5.0\n",
       "20     Transporter, The (2002)     5574     4.0\n",
       "24       Bruce Almighty (2003)     6373     3.5\n",
       "111           Belzebuth (2019)   204584     2.5\n",
       "72   Expendables 2, The (2012)    91485     4.0\n",
       "164  The Dark Web Tapes (2020)   287423     0.5\n",
       "54      Angels & Demons (2009)    68554     4.5\n",
       "76        Apartment 143 (2011)    96634     2.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 15375\n",
    "user_rated = data.dataset[data.dataset[\"UserID\"] == user_id]\n",
    "user_rated = pd.merge(movies[[\"MovieID\", \"Title\"]], user_rated, on=\"MovieID\", how=\"right\")\n",
    "user_rated = user_rated.sort_values(by=\"Rating\", ascending=False)\n",
    "user_rated = user_rated.reindex(columns=[\"Title\", \"MovieID\", \"Rating\"])\n",
    "user_rated.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 Shawshank Redemption, The (1994) 0.7871029376983643\n",
      "858 Godfather, The (1972) 0.7841407656669617\n",
      "1464 Lost Highway (1997) 0.7833184599876404\n",
      "3435 Double Indemnity (1944) 0.7824506759643555\n",
      "58559 Dark Knight, The (2008) 0.7813116312026978\n",
      "4848 Mulholland Drive (2001) 0.778712272644043\n",
      "1221 Godfather: Part II, The (1974) 0.7774827480316162\n",
      "44761 Brick (2005) 0.7748100161552429\n",
      "183461 Godless (2017) 0.7734577655792236\n",
      "4406 Man Who Shot Liberty Valance, The (1962) 0.7712690234184265\n"
     ]
    }
   ],
   "source": [
    "for m_id, rate in get_recommendation(user_id, model):\n",
    "    print(m_id, movies[movies[\"MovieID\"] == m_id][\"Title\"].values[0], rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocalopy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
